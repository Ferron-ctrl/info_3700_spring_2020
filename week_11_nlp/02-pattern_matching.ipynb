{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Name:\n",
    "### TODO\n",
    "Edit this cell and add your name to the top of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to assign for highlighting later\n",
    "DISPLAY_COLORS = {\n",
    "    \"PROBLEM\": \"#1f77b4\",\n",
    "    \"TREATMENT\": \"#ff7f0e\",\n",
    "    \"TEST\": \"#2ca02c\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching\n",
    "It's clear that spaCy's out-of-the-box NER is not going to fit our needs. In that case, we need to take matters into our own hands. SpaCy has several methods which enable us to do rule-based matching, while still having access to the many linguistic attributes which are classified by spaCy's statistical models. \n",
    "\n",
    "One such method is called the [EntityRuler](https://spacy.io/api/entityruler). This is a class which allows us extract entities by writing rules which will match tokens based on various attributes. The matches are then added to `doc.ents`. \n",
    "\n",
    "Let's load our model. However, since we know the NER model own't be useful for our task, we can leave that component out of our pipeline by passing in **\"ner\"** to the `spacy.load()` function.\n",
    "\n",
    "### TODO\n",
    "Create `nlp` without an NER component by calling `spacy.load()` and loading the **\"en_core_web_sm\"** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = ____.load(____, disable=\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's crate an object called `ruler`. It takes one argument: the `nlp` model which we loaded earlier.  This will be our rule-based NER matcher. When we first create it, it's blank - there are no labels or patterns included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "ruler = EntityRuler(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding to our pipeline\n",
    "In the last notebook, we saw what a spacy **pipeline** looked like. One of the most powerful features of spaCy is the ability to add to that pipeline. We'll add our `ruler` object to the pipeline so that our rule-based system is applied to texts when we call `nlp(text)`:\n",
    "\n",
    "### TODO\n",
    "Add the EntityRuler to the processing pipeline by calling `nlp.add_pipe()` and passing in the ruler as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "____.add_pipe(____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pattern matching\n",
    "\n",
    "A **pattern** for the `EntityRuler` takes the form of a Python **dictionary** with two keys:\n",
    "- `\"label\"`: The class of the entity we want to extract\n",
    "- `\"pattern\"`: The pattern we will match on in the text\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "{\"label\": \"LABEL\", \"pattern\": ...}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "The simplext form of this is going to be matching the **exact string**. For example, to match the exact strings **\"hypotension\"** and **\"CKD Stage 3\"**, we include patterns with those strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\"label\": \"PROBLEM\", \"pattern\": \"hypotension\"},\n",
    "    {\"label\": \"PROBLEM\", \"pattern\": \"CKD Stage 3\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we **add** these patterns to our ruler by calling `ruler.add()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting matches\n",
    "Now, let's process that same clinical text we saw in the last notebook and see what entities are extracted.\n",
    "\n",
    "### TODO\n",
    "Create a new `doc` by calling `nlp()` on the `text` variable. Then print out the entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"76 year old man with hypotension, CKD Stage 3, previously ckd stage two, status post RIJ line placement and Swan.\"\n",
    "doc = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we've now extracted the two patterns we defined in our **ruler**. Let's visualize this using `spacy.displacy()`, which offers visualizations for spaCy output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\", options={\"colors\": DISPLAY_COLORS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced pattern matching\n",
    "We could pass in simple strings to our `ruler` to extract exact matches. However, there may be lots of small variations in the text we want to extract, and it will grow cumbersome to type out every single possible string. Instead, we'll do some more advanced matching by using **token attribute matching**.\n",
    "\n",
    "SpaCy allows us to write patterns based on not only the exact text, but other linguistic attributes such as **part-of-speech tag**, **numerical properties**, **regular expressions**, and much more. \n",
    "\n",
    "## Example: Chronic Kidney Disease\n",
    "In the above text, we extracted two entities, including **\"CKD Stage 3\"**. However, there's a very similar span of text we want to extract: **\"ckd stage two\"**. We could write a new pattern to match this, but we would also want to match **\"CKD Stage 2\"**, **\"ckd Stage 4\"**, **\"CKD Stage 5\"**, etc. Instead of trying to think of the near-infinite number of variations, let's write one pattern which will match all of these clinical problems.\n",
    "\n",
    "An advanced pattern in spaCy is a Python **list**. Each element in that list is a **dictionary** representing each of the **tokens** (individual words) in a span of text. The **keys** of the dictionary represent the token attributes to look at and the **values** represent the values which should trigger a match:\n",
    "\n",
    "---\n",
    "```python\n",
    "[\n",
    "    {\"ATTRIBUTE\": value}, # First token\n",
    "    {\"ATTRIBUTE\": value}, # Second token\n",
    "    {\"ATTRIBUTE\": value} # Third token\n",
    "]\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now write a pattern which will match both **\"CKD Stage 3\"** and **\"ckd stage two\"**. What attributes are similar between these two spans of text? What is a general pattern that you could match?\n",
    "\n",
    "Both spans of text start out with the text **\"CKD\"**, although one is upper-case and one is lower-case. To match either, we will match on the **\"LOWER\"** attribute of the token:\n",
    "\n",
    "```python\n",
    "{\"LOWER\": \"ckd\"}\n",
    "```\n",
    "\n",
    "The second token is **\"Stage\"**, but again there's a difference in case. So let's use the **\"LOWER\"** attribute again:\n",
    "\n",
    "```python\n",
    "{\"LOWER\": \"stage\"}\n",
    "```\n",
    "\n",
    "Finally, the last token is a number. In this text there are **\"3\"** and **\"two\"**, but there could potentially be any number **1-5**. So let's just match any number. SpaCy can also recognize that the word **\"two\"** is a number by using the **\"LIKE_NUM\"** attribute, which is a boolean:\n",
    "\n",
    "```python\n",
    "{\"LIKE_NUM\": True}\n",
    "```\n",
    "\n",
    "When we put it all together, here is our pattern.\n",
    "\n",
    "### TODO\n",
    "Create a new pattern to match multiple CKD stages. Give the pattern a label of **\"PROBLEM\"**. Add the three dictionaries shown above in the **\"pattern\"** slot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd_pattern = {\n",
    "    \"label\": ____,\n",
    "    \"pattern\": [\n",
    "        ____, # Token 1\n",
    "        ____, # Token 2\n",
    "        ____ # Token 3\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add this to our **ruler** and see if we can match both spans of text. In `doc.ents`, we should expect to see both **\"CKD Stage 3\"** and **\"ckd stage two\"**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns([ckd_pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\", options={\"colors\": DISPLAY_COLORS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! Our pattern will also match other variations of chronic kidney disease. Feel free to try it out yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment entities\n",
    "We've now extracted all of the **\"PROBLEM\"** entities from our text. The other class we're interested in now is **\"TREATMENT\"**, which could include medication, procedures, or therapies. In our text, the two treatments are **\"RIJ line placement\"** and **\"Swan\"**. \n",
    "\n",
    "### TODO\n",
    "Add two new patterns to match these treatments. You could either match on exact strings or more complex attributes (like lower-casing) as seen in the examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_patterns = [\n",
    "    {\n",
    "        ____: \"TREATMENT\",\n",
    "        \"pattern\": ____\n",
    "    },\n",
    "    {\n",
    "        \"label\": ____,\n",
    "        ____: ____\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(new_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check which ents are extracted. Did you get all of the PROBLEM and TREATMENT entities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\", options={\"colors\": DISPLAY_COLORS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other pattern attributes\n",
    "In these last two examples, we saw some very simple ways to match patterns. But you can use many more attributes to match complicated patterns in text.\n",
    "\n",
    "Here are a few other useful pattern attributes you can use:\n",
    "- `{\"LOWER\": ...}`: Match on the lower-case string of a token. In clinical text, we'll usually use lower-case matching since clinical text is very inconsistent\n",
    "- `{\"LEMMA\": ...}`: Match on the **lemma** or **root word** of a token\n",
    "- `{\"POS\": ...}`: Match a word with a certa **part of speech tag**, like **\"ADJ\"**, **\"VERB\"**, or **\"NOUN\"**\n",
    "    \n",
    "- `{\"LOWER\": {\"IN\": [...]}}`: Match any word which is in a list of strings\n",
    "- `{\"LOWER\": {\"NOT_IN\": [...]}}`: Match any word which is **not** in a list of strings\n",
    "- `{\"LOWER\": {\"REGEX\": ...}}`: Match a regular expression\n",
    "- `{\"IS_TITLE\": True}`: Match any word which starts with a capital later\n",
    "\n",
    "See [spaCy's rule-based matching documentation](https://spacy.io/usage/rule-based-matching) and the [Matcher demo](https://explosion.ai/demos/matcher) for more explanation and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Write your own rule-based matcher\n",
    "\n",
    "Use the `EntityRuler` class to extract the following concepts from these texts:\n",
    "- \"PROBLEM\"\n",
    "- \"TREATMENT\"\n",
    "\n",
    "First, identify all of the **problems** and **treatments** in the texts below. Then write patterns and add them to `ruler` to extract them from the text. You can do either simple string matching (where the **\"pattern\"** value is a string and will match a string exactly) or more complex patterns (where the **\"pattern\"** value is a list of dicts).\n",
    "\n",
    "The number of patterns you write might vary, but I wrote **12 patterns** to match **15 entities**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"87-year-old man with htn and end-stage renal disease.\",\n",
    "    \"His wife recently died from end stage renal disease.\",\n",
    "    \"The patient was started on abx for his infection\",\n",
    "    \"There is continued mild-to-moderate congestive heart failure. \",\n",
    "    \"The patient is s/p median sternotomy and right thoracotomy.\",\n",
    "    \"The pt presents for ckd stage 4\",\n",
    "    \"He previously had CKD stage 3.\",\n",
    "    \"The patient presented to the emergency room with cough and fever, concern for infections.\",\n",
    "    \"Patient prescribed coumadin for her atrial fibrillation\",\n",
    "    \"Patient prescribed coumadin for her AF\",\n",
    "]\n",
    "\n",
    "# Let's join them together to make one long text so we can see all of the examples at the same time\n",
    "long_text = \"\\n\".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    {\"label\": ____, \"pattern\": ____},\n",
    "    # etc...\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(long_text)\n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the highlighted text and try to identify any additional \n",
    "# concepts which you should extract\n",
    "displacy.render(doc, style=\"ent\", options={\"colors\": DISPLAY_COLORS})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(doc.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "Rule-based systems can be very effective at extracting specific, targeted information from text. But they have disadvantages, such as that it is extremely manual effort to develop a comprehensive set of rules to extract concepts. \n",
    "\n",
    "In the next notebook we'll see how a **statistical model** can be used to extract information without writing specific rules.\n",
    "\n",
    "[03-statistical-nlp.ipynb](03-statistical-nlp.ipynb)\n",
    "\n",
    "## Week 11 Attendance\n",
    "Save this notebook as an HTML and submit it on Canvas for credit for Week 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
